{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\satvi\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\satvi\\anaconda3\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in c:\\users\\satvi\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\satvi\\anaconda3\\lib\\site-packages (2.24.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\satvi\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\satvi\\anaconda3\\lib\\site-packages (from requests) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\satvi\\anaconda3\\lib\\site-packages (from requests) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\satvi\\anaconda3\\lib\\site-packages (from requests) (2.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Python program to display all the header tags from ‘en.wikipedia.org/wiki/Main_Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List all the header tags :\n",
      "\n",
      "<h1 class=\"firstHeading\" id=\"firstHeading\">Main Page</h1>\n",
      "List all the header tags :\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfa-h2\"><span id=\"From_today.27s_featured_article\"></span><span class=\"mw-headline\" id=\"From_today's_featured_article\">From today's featured article</span></h2>\n",
      "List all the header tags :\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-dyk-h2\"><span class=\"mw-headline\" id=\"Did_you_know_...\">Did you know ...</span></h2>\n",
      "List all the header tags :\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-itn-h2\"><span class=\"mw-headline\" id=\"In_the_news\">In the news</span></h2>\n",
      "List all the header tags :\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-otd-h2\"><span class=\"mw-headline\" id=\"On_this_day\">On this day</span></h2>\n",
      "List all the header tags :\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfl-h2\"><span id=\"From_today.27s_featured_list\"></span><span class=\"mw-headline\" id=\"From_today's_featured_list\">From today's featured list</span></h2>\n",
      "List all the header tags :\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfp-h2\"><span id=\"Today.27s_featured_picture\"></span><span class=\"mw-headline\" id=\"Today's_featured_picture\">Today's featured picture</span></h2>\n",
      "List all the header tags :\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-other\"><span class=\"mw-headline\" id=\"Other_areas_of_Wikipedia\">Other areas of Wikipedia</span></h2>\n",
      "List all the header tags :\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-sister\"><span id=\"Wikipedia.27s_sister_projects\"></span><span class=\"mw-headline\" id=\"Wikipedia's_sister_projects\">Wikipedia's sister projects</span></h2>\n",
      "List all the header tags :\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-lang\"><span class=\"mw-headline\" id=\"Wikipedia_languages\">Wikipedia languages</span></h2>\n",
      "List all the header tags :\n",
      "\n",
      "<h2>Navigation menu</h2>\n",
      "List all the header tags :\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-personal-label\">\n",
      "<span>Personal tools</span>\n",
      "</h3>\n",
      "List all the header tags :\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-namespaces-label\">\n",
      "<span>Namespaces</span>\n",
      "</h3>\n",
      "List all the header tags :\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-variants-label\">\n",
      "<span>Variants</span>\n",
      "</h3>\n",
      "List all the header tags :\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-views-label\">\n",
      "<span>Views</span>\n",
      "</h3>\n",
      "List all the header tags :\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-cactions-label\">\n",
      "<span>More</span>\n",
      "</h3>\n",
      "List all the header tags :\n",
      "\n",
      "<h3>\n",
      "<label for=\"searchInput\">Search</label>\n",
      "</h3>\n",
      "List all the header tags :\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-navigation-label\">\n",
      "<span>Navigation</span>\n",
      "</h3>\n",
      "List all the header tags :\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-interaction-label\">\n",
      "<span>Contribute</span>\n",
      "</h3>\n",
      "List all the header tags :\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-tb-label\">\n",
      "<span>Tools</span>\n",
      "</h3>\n",
      "List all the header tags :\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-coll-print_export-label\">\n",
      "<span>Print/export</span>\n",
      "</h3>\n",
      "List all the header tags :\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-wikibase-otherprojects-label\">\n",
      "<span>In other projects</span>\n",
      "</h3>\n",
      "List all the header tags :\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-lang-label\">\n",
      "<span>Languages</span>\n",
      "</h3>\n"
     ]
    }
   ],
   "source": [
    "page = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "soup = bs(page.text, 'html.parser')\n",
    "headers = soup.find_all(['h1', 'h2','h3'])\n",
    "for i in headers:\n",
    "    print('List all the header tags :',i,sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of Release)and dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.imdb.com/list/ls055592025/?sort=user_rating,desc&st_dt=&mode=detail&page=1'\n",
    "response=requests.get(url)\n",
    "soup=bs(response.content,'html.parser')\n",
    "movie_name=[]\n",
    "year_of_release=[]\n",
    "IMDB_rating=[]\n",
    "movie_data=soup.find_all('div',attrs={'class':'lister-item-content'})\n",
    "for store in movie_data:\n",
    "    name=store.h3.a.text\n",
    "    movie_name.append(name)\n",
    "    \n",
    "    year=store.h3.find('span',class_='lister-item-year text-muted unbold').text.replace('(','').replace(')','')\n",
    "    year_of_release.append(year)\n",
    "    \n",
    "    rating=store.find('div',class_='ipl-rating-star small').text.replace('\\n','')\n",
    "    IMDB_rating.append(rating)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>IMDB Rating</th>\n",
       "      <th>Year Of Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>9</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>9</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Wuthering Heights</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>West Side Story</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>American Graffiti</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Terms of Endearment</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>An American in Paris</td>\n",
       "      <td>7.2</td>\n",
       "      <td>1951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Movie Name IMDB Rating Year Of Release\n",
       "0   The Shawshank Redemption         9.3            1994\n",
       "1              The Godfather         9.2            1972\n",
       "2     The Godfather: Part II           9            1974\n",
       "3               12 Angry Men           9            1957\n",
       "4               Pulp Fiction         8.9            1994\n",
       "..                       ...         ...             ...\n",
       "95         Wuthering Heights         7.6            1939\n",
       "96           West Side Story         7.5            1961\n",
       "97         American Graffiti         7.4            1973\n",
       "98       Terms of Endearment         7.4            1983\n",
       "99      An American in Paris         7.2            1951\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_DF=pd.DataFrame({'Movie Name':movie_name,'IMDB Rating':IMDB_rating,'Year Of Release':year_of_release},index=range(0,100,1))\n",
    "movie_DF.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.To display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release) and dataframe \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.imdb.com/list/ls056092300/?sort=user_rating,desc&st_dt=&mode=detail&page=1'\n",
    "response=requests.get(url)\n",
    "soup=bs(response.content,'html.parser')\n",
    "movie_name=[]\n",
    "year_of_release=[]\n",
    "IMDB_rating=[]\n",
    "movie_data=soup.find_all('div',attrs={'class':'lister-item-content'})\n",
    "for store in movie_data:\n",
    "    name=store.h3.a.text\n",
    "    movie_name.append(name)\n",
    "    \n",
    "    year=store.h3.find('span',class_='lister-item-year text-muted unbold').text.replace('(','').replace(')','')\n",
    "    year_of_release.append(year)\n",
    "    \n",
    "    rating=store.find('div',class_='ipl-rating-star small').text.replace('\\n','')\n",
    "    IMDB_rating.append(rating)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>IMDB Rating</th>\n",
       "      <th>Year Of Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Goopy Gyne Bagha Byne</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sagara Sangamam</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pather Panchali</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pushpaka Vimana</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Vanaja</td>\n",
       "      <td>7.1</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Amma Ariyan</td>\n",
       "      <td>7</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Chandni</td>\n",
       "      <td>6.8</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Neecha Nagar</td>\n",
       "      <td>6.8</td>\n",
       "      <td>1946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>English, August</td>\n",
       "      <td>6.8</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Movie Name IMDB Rating Year Of Release\n",
       "0   Goopy Gyne Bagha Byne         8.8            1969\n",
       "1         Sagara Sangamam         8.8            1983\n",
       "2                 Nayakan         8.7            1987\n",
       "3         Pather Panchali         8.6            1955\n",
       "4         Pushpaka Vimana         8.6            1987\n",
       "..                    ...         ...             ...\n",
       "95                 Vanaja         7.1            2006\n",
       "96            Amma Ariyan           7            1986\n",
       "97                Chandni         6.8            1989\n",
       "98           Neecha Nagar         6.8            1946\n",
       "99        English, August         6.8            1994\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Movies=pd.DataFrame({'Movie Name':movie_name,'IMDB Rating':IMDB_rating,'Year Of Release':year_of_release},index=range(0,100,1))\n",
    "Movies.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Write a python program to scrap book name, author name, genre and book review of any 5 books from ‘www.bookpage.com’\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://bookpage.com/features/26265-sweet-substantial-romance#.YMn0y2gzZPY'\n",
    "response=requests.get(url)\n",
    "soup=bs(response.content,'html.parser')\n",
    "book_name=[]\n",
    "author_name=[]\n",
    "genre=[]\n",
    "book_review=[]\n",
    "name=soup.find_all('h4',attrs={'class':'italic'})\n",
    "for i in name:\n",
    "    book=i.text.replace('*','').replace('\\n','')\n",
    "    book_name.append(book)\n",
    "author=soup.find_all('p',class_='sans bold')\n",
    "for j in  author:   \n",
    "    authorname=j.a.text\n",
    "    author_name.append(authorname)\n",
    "genric=soup.find_all('p',class_='genre-links sans')\n",
    "for k in genric:\n",
    "    genrous=k.a.text\n",
    "    genre.append(genrous)\n",
    "review=soup.find_all('div',class_='article-body')\n",
    "for l in review:\n",
    "    bookreview=l.text.replace('\\n\\n','')\n",
    "    book_review.append(bookreview)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['These five queer romances are the perfect blend of swoon-inducing and serious, balancing delicious escapism with examinations of thorny issues such as family expectations, the grieving process and the corrosive influence of the British class system.★\\xa0The Queer Principles of Kit Webb\\nSet in Georgian-era England, Cat Sebastian’s The Queer Principles of Kit Webb takes a charming, gratifyingly original perspective on love across the class divide. The titular Kit is a gruff retired highwayman-turned-coffee house proprietor who truly despises the aristocracy. Edward Percy Talbot, Lord Holland, is one of the British class system’s greatest beneficiaries. A dandy and marquess, Percy is the heir to a prosperous dukedom held by one of England’s most notorious abusers of aristocratic privilege and power.\\xa0\\nKit is skeptical when the conspicuously costumed and brazenly flirtatious popinjay starts to haunt his coffee shop on a daily basis. Percy’s position in the world is more precarious than one would expect, however, and he approaches the disillusioned highwayman to do one last job. Their mission: steal a book that Percy’s father keeps on his person at all times, one whose contents will provide leverage and financial security for Percy, his stepmother and his infant half -sister.\\xa0\\nKit retired after his last job went wrong, incurring a serious injury and losing his best friend and partner. Because of this, he trains Percy to take the main role in the heist, putting them in close physical proximity.\\xa0\\nTheir sexual tension is a living, breathing thing on the page, but mercifully, Sebastian doesn’t leave them in want for long. And there’s plenty of sparkling dialogue to go with their physical connection. Kit has very clear opinions about the privilege Percy is fighting to protect, and their conversations about class and politics are uniformly excellent and fascinating. Kit Webb will surprise and delight not only fans of Sebastian and queer historical romance but also readers who are new to both.\\n—Carole V. Bell\\nHard Sell\\nHudson Lin’s intricate, weighty Hard Sell follows the ramifications of a sexy one-night stand. A business acquisition reunites private equity investor Danny Ip and finance guru Tobin Lok seven years after the childhood friends finally gave in to their mutual attraction. Danny is interested in buying and shutting down WesTec, a buzzy tech startup. As an independent financial consultant, Tobin has been tasked with helping WesTec avoid bankruptcy, or at the very least, making sure Danny doesn’t undervalue the company in order to make a profit. The spark between them remains despite the time and distance—but so do the complications around their potential romance, which extend beyond Tobin’s tricky professional position.\\xa0\\nWhen they were growing up, Tobin’s tightknit family was big and meddlesome, but it was also a bastion of safety and belonging to Danny, who was Tobin’s older brother’s best friend. As an only child whose single mother was constantly working, Danny thought the Loks’ house was heaven. But for Tobin, the youngest son with a desperate crush on Danny, his family’s “well-intentioned smothering” was and remains difficult.\\nLin creates a loving, traditional family with the Loks, but she also shows their tone-deaf attitudes toward Tobin’s life as a gay man in a very real, palpable way. Tobin’s mother calls regularly, and his brother sends photos of Tobin’s nephew. Tobin yearns for acceptance beyond superficial inclusion, but he has no idea whether a potential relationship with Danny would make things better or immeasurably worse.\\nMuch is at stake for these men, who have banked their love for one another for nearly a decade. But when Danny and Tobin finally give in to their hearts, the result is euphoric.\\n—Dolly R. Sickles\\n★\\xa0Satisfaction Guaranteed\\nWhen Cade Elgin travels from her New York City home to Portland, Oregon, for her aunt’s funeral, she’s totally unprepared for her inheritance: her aunt’s sex-toy store, which is on the verge of bankruptcy. Cade is a careful, conservative businesswoman, with no room in her life for shenanigans or the wacky gold lamé preferences of her fellow funeralgoers. Fortunately, her new business partner-in-inheritance, Selena Mathis, has the passion and whimsy to balance Cade’s business prowess. Having taken a self-imposed oath of celibacy after some relationship troubles, Selena doesn’t want anything to do with the unexpected attraction she feels for Cade.\\xa0\\nOregon writer Karelia Stetz-Waters employs humor like a finely trained chef, sprinkling in lighthearted moments precisely when heavier topics require a little levity. Death, inheritance and responsibility are weighty conversations for any new romantic duo, but Cade and Selena’s ability to synchronize with one another is remarkable. Satisfaction Guaranteed is a standout romance with humor, heart and two characters who step out of their comfort zones together.\\xa0\\n—Dolly R. Sickles\\nHow to Find a Princess\\nAlyssa Cole returns with the second installment of her Runaway Royals series, How to Find a Princess, and it’s just as fun, smart and challenging as last year’s How to Catch a Queen. Readers can count on this series to deliver total immersion into a sweeping, romantic alternate reality and intelligent, complicated female characters.\\xa0\\nBeznaria Chetchevaliere is an investigator for the World Federation of Monarchies, and she’s searching for Makeda Hicks, the lost heir of the idyllic kingdom of Ibarania. Decades ago, Makeda’s grandmother had a hot summer fling with the then-heir to the throne, Prince Keshan. The pragmatic Makeda is thrown by this information, which reveals that a family tall tale is not only true but also potentially life-changing. She’s already reeling from recently losing her job and her girlfriend, so seeing the magic in her potentially royal lineage feels impossible; rather, it seems like a solemn, daunting duty she never asked for.\\xa0\\nCole’s allusions to the animated 1997 film Anastasia will delight fans, and anyone fascinated by the story of the Romanov princess will be tickled, but Cole’s take on the lost heir mythos is a more mature tale with hefty stakes.\\n—Dolly R. Sickles\\n★\\xa0Rosaline Palmer Takes the Cake\\nIn Rosaline Palmer Takes the Cake, Alexis Hall (Boyfriend Material) explores contemporary class and societal expectations through believable characters who struggle with substantial pain and self-doubt.\\xa0\\nRosaline is a bisexual woman with a privileged pedigree. Both of her parents are highly successful doctors, and she grew up in one of London’s most affluent districts. But after a surprise pregnancy during her time at Cambridge, she’s now a doting mom who makes delicious baked creations with her precocious 8-year-old daughter, Amelie.\\xa0\\nCompeting on the BBC’s popular baking competition show “Baked Expectations” could be Rosaline’s ticket out of financial disaster. But even though she rejected the path her parents chose for her, Rosaline hasn’t managed to throw off the values and expectations they inculcated in her. When she arrives at the competition to find it full of potential love interests, she sees them through a class-based filter. Rosaline may stand up to biphobia, especially around her daughter, but she also repeatedly, reflexively upholds class and gender biases. For example, she deems her lovely co-star Harry off-limits because of his working-class accent and profession.\\xa0\\nDespite the heavy subject matter, this rom-com provides a cornucopia of cringey, laugh-out-loud moments. Its combination of social insight and comedy makes for a surprisingly twisty tale. (Rosaline has multiple love interests, and it’s not clear who she will choose for large swaths of the story.) This complexity also means that the central romance doesn’t get as much page time as one would expect. The scenes between Rosaline and her eventual soul mate are gorgeous but scarce, which might leave some readers wanting more. Nonetheless, Hall’s creation is a joy—a deeply emotional and ultimately rewarding story about a woman finding her true path and true love, surrounded by delicious baked goods on a BBC soundstage.\\xa0\\n—Carole V. Bell']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cat Sebastian',\n",
       " 'Hudson Lin',\n",
       " 'Karelia Stetz-Waters',\n",
       " 'Alyssa Cole',\n",
       " 'Alexis Hall']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['★ The Queer Principles of Kit Webb',\n",
       " 'Hard Sell',\n",
       " '★ Satisfaction Guaranteed',\n",
       " 'How to Find a Princess',\n",
       " '★ Rosaline Palmer Takes the Cake']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "response=requests.get(url)\n",
    "soup=bs(response.content,'html.parser')\n",
    "mens_team=[]\n",
    "records_for_matches=[]\n",
    "points=[]\n",
    "rating=[]\n",
    "teams=soup.find_all('span',class_='u-hide-phablet')\n",
    "for i in teams:\n",
    "    mensteam=i.text\n",
    "    mens_team.append(mensteam)\n",
    "records=soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "for j in records:\n",
    "    matchesrecord=j.text\n",
    "    records_for_matches.append(matchesrecord)\n",
    "score=soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "for k in score:\n",
    "    ranking=k.text\n",
    "    points.append(ranking) \n",
    "rates=soup.find_all('td','table-body__cell u-text-right rating') \n",
    "for l in rates:\n",
    "    star=l.text\n",
    "    rating.append(star)                    \n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New Zealand',\n",
       " 'Australia',\n",
       " 'India',\n",
       " 'England',\n",
       " 'South Africa',\n",
       " 'Pakistan',\n",
       " 'Bangladesh',\n",
       " 'West Indies',\n",
       " 'Sri Lanka',\n",
       " 'Afghanistan']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mens_team[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['25', '2,945', '29', '3,344', '27', '3,100', '20', '2,137', '24', '2,323']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_for_matches[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['118', '115', '115', '107', '97', '90', '82', '78', '62', '48']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['25', '2,945', '29', '3,344', '27', '3,100', '20', '2,137', '24', '2,323']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii) Top 10 ODI Batsmen in men along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting'\n",
    "response=requests.get(url)\n",
    "soup=bs(response.content,'html.parser')\n",
    "batsman_name=[]\n",
    "records_of_team=[]\n",
    "rating=[]\n",
    "batsman=soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "for j in batsman:\n",
    "    player=j.a.text\n",
    "    batsman_name.append(player)\n",
    "records=soup.find_all('td',class_='table-body__cell u-text-right u-hide-phablet')\n",
    "for i in records:\n",
    "    team=i.text.replace('\\n' ,'')\n",
    "    records_of_team.append(team)\n",
    "ratings=soup.find_all('td',class_='table-body__cell rating')\n",
    "for k in ratings:\n",
    "    star=k.text\n",
    "    rating.append(star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['                                911 v England, 12/07/2018                        ',\n",
       " '                                885 v Sri Lanka, 06/07/2019                        ',\n",
       " '                                841 v Bangladesh, 05/06/2019                        ',\n",
       " '                                798 v England, 25/06/2019                        ',\n",
       " '                                796 v India, 26/03/2021                        ',\n",
       " '                                778 v South Africa, 07/04/2021                        ',\n",
       " '                                820 v Australia, 06/07/2019                        ',\n",
       " '                                880 v Pakistan, 26/01/2017                        ',\n",
       " '                                808 v Bangladesh, 17/05/2019                        ',\n",
       " '                                813 v Sri Lanka, 10/03/2019                        ']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_of_team[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['857', '825', '801', '791', '785', '778', '778', '773', '773', '756']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Virat Kohli',\n",
       " 'Rohit Sharma',\n",
       " 'Ross Taylor',\n",
       " 'Aaron Finch',\n",
       " 'Jonny Bairstow',\n",
       " 'Fakhar Zaman',\n",
       " 'Francois du Plessis',\n",
       " 'David Warner',\n",
       " 'Shai Hope',\n",
       " 'Quinton de Kock']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batsman_name[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii) Top 10 ODI bowlers along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling'\n",
    "response=requests.get(url)\n",
    "soup=bs(response.content,'html.parser')\n",
    "bowlers=[]\n",
    "team_records=[]\n",
    "rating=[]\n",
    "odi=soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "for m in odi:\n",
    "    odibowlers=m.a.text.replace('\\n','')\n",
    "    bowlers.append(odibowlers)\n",
    "records=soup.find_all('td','table-body__cell u-text-right u-hide-phablet')\n",
    "for j in records:\n",
    "    team=j.text.replace('\\n','')\n",
    "    team_records.append(team)\n",
    "rate=soup.find_all('td',class_='table-body__cell rating')\n",
    "for k in rate:\n",
    "        star=k.text\n",
    "        rating.append(star)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['713', '708', '691', '690', '666', '665', '660', '646', '645', '638']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['                                725 v Sri Lanka, 25/05/2021                        ',\n",
       " '                                712 v Ireland, 24/01/2021                        ',\n",
       " '                                691 v Bangladesh, 26/03/2021                        ',\n",
       " '                                841 v West Indies, 01/11/2018                        ',\n",
       " '                                724 v England, 29/05/2017                        ',\n",
       " '                                676 v New Zealand, 14/07/2019                        ',\n",
       " '                                733 v England, 26/01/2018                        ',\n",
       " '                                729 v Pakistan, 12/06/2019                        ',\n",
       " '                                695 v West Indies, 14/12/2018                        ',\n",
       " '                                663 v Sri Lanka, 02/10/2019                        ']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_records[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mehedi Hasan',\n",
       " 'Mujeeb Ur Rahman',\n",
       " 'Matt Henry',\n",
       " 'Jasprit Bumrah',\n",
       " 'Kagiso Rabada',\n",
       " 'Chris Woakes',\n",
       " 'Josh Hazlewood',\n",
       " 'Pat Cummins',\n",
       " 'Mustafizur Rahman',\n",
       " 'Mohammad Amir']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bowlers[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "response=requests.get(url)\n",
    "soup=bs(response.content,'html.parser')\n",
    "womens_team=[]\n",
    "matches=[]\n",
    "points=[]\n",
    "rating=[]\n",
    "team=soup.find_all('span','u-hide-phablet')\n",
    "for i in team:\n",
    "    number=i.text\n",
    "    womens_team.append(number)\n",
    "played=soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "for j in played:\n",
    "    matchesplayed=j.text\n",
    "    matches.append(matchesplayed)\n",
    "score=soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "for l in score:\n",
    "    Points=l.text\n",
    "    points.append(Points)\n",
    "rates=soup.find_all('td','table-body__cell u-text-right rating')\n",
    "for k in rates:\n",
    "    star=k.text\n",
    "    rating.append(star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['24', '2,828', '17', '1,993', '20', '2,226', '21', '1,947', '12', '1,025']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['24', '2,828', '17', '1,993', '20', '2,226', '21', '1,947', '12', '1,025']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['118', '117', '111', '93', '85', '73', '61', '47', '13']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Australia',\n",
       " 'South Africa',\n",
       " 'England',\n",
       " 'India',\n",
       " 'New Zealand',\n",
       " 'West Indies',\n",
       " 'Pakistan',\n",
       " 'Bangladesh',\n",
       " 'Sri Lanka',\n",
       " 'Ireland']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "womens_team[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Top 10 women’s ODI players along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting'\n",
    "response=requests.get(url)\n",
    "soup=bs(response.content,'html.parser')\n",
    "women_player=[]\n",
    "team_records=[]\n",
    "rating=[]\n",
    "women=soup.find_all('td','table-body__cell rankings-table__name name')\n",
    "for i in women:\n",
    "    player=i.a.text.replace('\\n','')\n",
    "    women_player.append(player)\n",
    "records=soup.find_all('td',class_='table-body__cell u-text-right u-hide-phablet')\n",
    "for j in records:\n",
    "    teams=j.text.replace('\\n','')\n",
    "    team_records.append(teams)\n",
    "rates=soup.find_all('td',class_='table-body__cell rating')\n",
    "for k in rates:\n",
    "    star=k.text\n",
    "    rating.append(star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['758', '756', '746', '723', '715', '710', '709', '685', '683', '679']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['                                773 v India, 14/03/2021                        ',\n",
       " '                                756 v New Zealand, 10/04/2021                        ',\n",
       " '                                765 v India, 02/03/2012                        ',\n",
       " '                                834 v New Zealand, 24/02/2016                        ',\n",
       " '                                756 v Australia, 02/03/2017                        ',\n",
       " '                                797 v England, 28/02/2019                        ',\n",
       " '                                839 v Australia, 24/12/2004                        ',\n",
       " '                                712 v India, 25/02/2019                        ',\n",
       " '                                725 v India, 07/03/2021                        ',\n",
       " '                                766 v West Indies, 11/09/2019                        ']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_records[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lizelle Lee',\n",
       " 'Alyssa Healy',\n",
       " 'Stafanie Taylor',\n",
       " 'Meg Lanning',\n",
       " 'Amy Satterthwaite',\n",
       " 'Smriti Mandhana',\n",
       " 'Mithali Raj',\n",
       " 'Natalie Sciver',\n",
       " 'Laura Wolvaardt',\n",
       " 'Ellyse Perry']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "women_player[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder'\n",
    "response=requests.get(url)\n",
    "soup=bs(response.content,'html.parser')\n",
    "womens_odi_all_rounder=[]\n",
    "team_records=[]\n",
    "rating=[]\n",
    "allrounder=soup.find_all('td','table-body__cell rankings-table__name name')\n",
    "for i in allrounder:\n",
    "    womensodi=i.a.text\n",
    "    womens_odi_all_rounder.append(womensodi)\n",
    "teams=soup.find_all('td','table-body__cell u-text-right u-hide-phablet')\n",
    "for j in teams:\n",
    "    records=j.text.replace('\\n','')\n",
    "    team_records.append(records)\n",
    "rates=soup.find_all('td',class_='table-body__cell rating')\n",
    "for k in rates:\n",
    "    star=k.text\n",
    "    rating.append(star)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['418', '410', '349', '343', '307', '252', '243', '242', '236', '236']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['                                548 v West Indies, 11/09/2019                        ',\n",
       " '                                559 v New Zealand, 10/10/2013                        ',\n",
       " '                                349 v New Zealand, 28/02/2021                        ',\n",
       " '                                397 v South Africa, 09/10/2019                        ',\n",
       " '                                308 v West Indies, 11/09/2019                        ',\n",
       " '                                256 v New Zealand, 04/04/2021                        ',\n",
       " '                                421 v Sri Lanka, 11/02/2019                        ',\n",
       " '                                305 v Australia, 05/10/2020                        ',\n",
       " '                                247 v Australia, 07/04/2021                        ',\n",
       " '                                270 v Sri Lanka, 16/03/2019                        ']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_records[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ellyse Perry',\n",
       " 'Stafanie Taylor',\n",
       " 'Natalie Sciver',\n",
       " 'Deepti Sharma',\n",
       " 'Jess Jonassen',\n",
       " 'Ashleigh Gardner',\n",
       " 'Dane van Niekerk',\n",
       " 'Sophie Devine',\n",
       " 'Amelia Kerr',\n",
       " 'Katherine Brunt']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "womens_odi_all_rounder[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  7. Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The scraped data should include Product Name, Price, Image URL and Average Rating\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Oppo A31 (Fantasy White, 6GB RAM, 128GB Storage) with No Cost EMI/Additional Exchange Offers',\n",
       " 'Redmi 9A (Nature Green, 2GB RAM, 32GB Storage) | 2GHz Octa-core Helio G25 Processor | 5000 mAh Battery',\n",
       " 'Redmi 9 (Sky Blue, 4GB RAM, 64GB Storage)| 5000 mAh| 2.3GHz Mediatek Helio G35 Octa core Processor',\n",
       " 'Redmi 9 Power (Mighty Black, 6GB RAM, 128GB Storage) - 6000mAh Battery |FHD+ Screen| 48MP Quad Camera | Snapdragon 662 Processor',\n",
       " 'Samsung Galaxy M12 (Blue,4GB RAM, 64GB Storage) 6000 mAh with 8nm Processor | True 48 MP Quad Camera | 90Hz Refresh Rate',\n",
       " 'Redmi Note 9 (Pebble Grey, 4GB RAM 64GB Storage) - 48MP Quad Camera & Full HD+ Display',\n",
       " 'Samsung Galaxy M11 (Metallic Blue, 4GB RAM, 64GB Storage) with No Cost EMI/Additional Exchange Offers',\n",
       " 'Oppo A31 (Mystery Black, 6GB RAM, 128GB Storage) with No Cost EMI/Additional Exchange Offers',\n",
       " 'TECNO Spark 7T(Magnet Black, 4GB RAM,64GB Storage) 6000 mAh Battery| 48 MP AI Dual Rear Camera',\n",
       " 'Samsung Galaxy M02s (Blue,4GB RAM, 64GB Storage) | 5000 mAh | Triple Camera',\n",
       " 'Redmi Note 10 (Aqua Green, 6GB RAM, 128GB Storage) - Amoled Dot Display | 48MP Sony Sensor IMX582 | Snapdragon 678 Processor',\n",
       " 'Samsung Galaxy M11 (Black, 4GB RAM, 64GB Storage) with No Cost EMI/Additional Exchange Offers',\n",
       " 'Samsung Galaxy M01 Core (Black, 2GB RAM, 32GB Storage) with No Cost EMI/Additional Exchange Offers',\n",
       " 'Redmi 9 (Carbon Black, 4GB RAM, 64GB Storage) | 5000 mAh| 2.3GHz Mediatek Helio G35 Octa core Processor',\n",
       " 'Redmi 9A (Sea Blue 2GB RAM 32GB Storage) | 2GHz Octa-core Helio G25 Processor | 5000 mAh Battery',\n",
       " 'Redmi 9A (Midnight Black 2GB RAM 32GB Storage) | 2GHz Octa-core Helio G25 Processor | 5000 mAh Battery']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url='https://www.amazon.in/s?k=mobile+phones+under+20000&ref=nb_sb_noss_1'\n",
    "response=requests.get(url)\n",
    "soup=bs(response.content,'html.parser')\n",
    "Product_name=[]\n",
    "Product=soup.find_all('span',class_='a-size-medium a-color-base a-text-normal')\n",
    "for i in Product:\n",
    "    name=i.text\n",
    "    Product_name.append(name)\n",
    "Product_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11,490',\n",
       " '6,799',\n",
       " '8,799',\n",
       " '12,999',\n",
       " '10,999',\n",
       " '8,999',\n",
       " '8,999',\n",
       " '9,999',\n",
       " '14,499',\n",
       " '8,999',\n",
       " '6,199',\n",
       " '8,799',\n",
       " '6,799',\n",
       " '6,799']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url='https://www.amazon.in/s?k=mobile+phones+under+20000&ref=nb_sb_noss_1'\n",
    "response=requests.get(url)\n",
    "soup=bs(response.content,'html.parser')\n",
    "price=[]\n",
    "cost=soup.find_all('span',class_='a-price-whole')\n",
    "for j in cost:\n",
    "    amount=j.text\n",
    "    price.append(amount)\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://m.media-amazon.com/images/I/61IhTtJUXJL._AC_UY218_.jpg',\n",
       " 'https://m.media-amazon.com/images/I/71sxlhYhKWL._AC_UY218_.jpg',\n",
       " 'https://m.media-amazon.com/images/I/71A9Vo1BatL._AC_UY218_.jpg',\n",
       " 'https://m.media-amazon.com/images/I/61LHaUOhehL._AC_UY218_.jpg',\n",
       " 'https://m.media-amazon.com/images/I/71yYaNztZ0L._AC_UY218_.jpg',\n",
       " 'https://m.media-amazon.com/images/I/71X5I1cVfbL._AC_UY218_.jpg',\n",
       " 'https://m.media-amazon.com/images/I/71GQUxuSpnS._AC_UY218_.jpg',\n",
       " 'https://m.media-amazon.com/images/I/71KCwNV6MuL._AC_UY218_.jpg',\n",
       " 'https://m.media-amazon.com/images/I/81EHVlbWOaS._AC_UY218_.jpg',\n",
       " 'https://m.media-amazon.com/images/I/71wkpcIfqdL._AC_UY218_.jpg',\n",
       " 'https://m.media-amazon.com/images/I/71-BcSc9rhS._AC_UY218_.jpg',\n",
       " 'https://m.media-amazon.com/images/I/710jkZNub3S._AC_UY218_.jpg',\n",
       " 'https://m.media-amazon.com/images/I/71AYb2AGHXL._AC_UY218_.jpg',\n",
       " 'https://m.media-amazon.com/images/I/716nHhG9SWL._AC_UY218_.jpg',\n",
       " 'https://m.media-amazon.com/images/I/71sxlhYhKWL._AC_UY218_.jpg',\n",
       " 'https://m.media-amazon.com/images/I/71sxlhYhKWL._AC_UY218_.jpg']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url='https://www.amazon.in/s?k=mobile+phones+under+20000&ref=nb_sb_noss_1'\n",
    "response=requests.get(url)\n",
    "soup=bs(response.text,'html.parser')\n",
    "image_url=[]\n",
    "images=soup.find_all('img',class_='s-image')\n",
    "for image in images:\n",
    "    image_url.append(image['src'])\n",
    "image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.2 out of 5 stars',\n",
       " '4.2 out of 5 stars',\n",
       " '4.2 out of 5 stars',\n",
       " '4.2 out of 5 stars',\n",
       " '4.1 out of 5 stars',\n",
       " '4.2 out of 5 stars',\n",
       " '4.2 out of 5 stars',\n",
       " '4.1 out of 5 stars',\n",
       " '4.1 out of 5 stars',\n",
       " '4.2 out of 5 stars',\n",
       " '4.2 out of 5 stars',\n",
       " '4.2 out of 5 stars',\n",
       " '4.2 out of 5 stars']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url='https://www.amazon.in/s?k=mobile+phones+under+20000&ref=nb_sb_noss_1'\n",
    "response=requests.get(url)\n",
    "soup=bs(response.content,'html.parser')\n",
    "average_rating=[]\n",
    "rating=soup.find_all('i',class_='a-icon a-icon-star-small a-star-small-4 aok-align-bottom')\n",
    "for l in rating:\n",
    "    avg=l.text\n",
    "    average_rating.append(avg)\n",
    "average_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   8. Write a python program to extract information about the local weather from the National Weather Service website of USA, https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day \n",
    "extended forecast display for the city. The data should include period, short description, temperature and \n",
    "description.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Today',\n",
       " 'Tonight',\n",
       " 'Tuesday',\n",
       " 'Tuesday Night',\n",
       " 'Wednesday',\n",
       " 'Wednesday Night',\n",
       " 'Thursday',\n",
       " 'Thursday Night',\n",
       " 'Friday',\n",
       " 'Friday Night',\n",
       " 'Saturday',\n",
       " 'Saturday Night',\n",
       " 'Sunday']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url='https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.YM85uhHitPY'\n",
    "response=requests.get(url)\n",
    "soup=bs(response.content,'html.parser')\n",
    "period=[]\n",
    "Period=soup.find_all('div',class_='col-sm-2 forecast-label')\n",
    "for i in Period:\n",
    "    days=i.b.text\n",
    "    period.append(days)\n",
    "period\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mostly cloudy, then gradually becoming sunny, with a high near 69. Breezy, with a west southwest wind 10 to 15 mph increasing to 17 to 22 mph in the afternoon. Winds could gust as high as 29 mph. ',\n",
       " 'Increasing clouds, with a low around 59. Southwest wind 15 to 20 mph decreasing to 8 to 13 mph after midnight. Winds could gust as high as 25 mph. ',\n",
       " 'Mostly cloudy, then gradually becoming sunny, with a high near 70. West southwest wind 7 to 12 mph increasing to 16 to 21 mph in the afternoon. Winds could gust as high as 26 mph. ',\n",
       " 'Partly cloudy, with a low around 58. Southwest wind 16 to 21 mph decreasing to 10 to 15 mph after midnight. Winds could gust as high as 26 mph. ',\n",
       " 'Sunny, with a high near 69. West southwest wind 6 to 11 mph increasing to 12 to 17 mph in the afternoon. Winds could gust as high as 23 mph. ',\n",
       " 'Partly cloudy, with a low around 56.',\n",
       " 'Sunny, with a high near 68.',\n",
       " 'Partly cloudy, with a low around 56.',\n",
       " 'Mostly sunny, with a high near 69.',\n",
       " 'Partly cloudy, with a low around 57.',\n",
       " 'Sunny, with a high near 72.',\n",
       " 'Partly cloudy, with a low around 57.',\n",
       " 'Sunny, with a high near 74.']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url='https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.YM85uhHitPY'\n",
    "response=requests.get(url)\n",
    "soup=bs(response.content,'html.parser')\n",
    "period_description=[]\n",
    "description=soup.find_all('div',class_='col-sm-10 forecast-text')\n",
    "for j in description:\n",
    "    period=j.text\n",
    "    period_description.append(period)\n",
    "period_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['High: 69 °F', 'High: 70 °F', 'High: 69 °F', 'High: 68 °F', 'High: 69 °F']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url='https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.YM85uhHitPY'\n",
    "response=requests.get(url)\n",
    "soup=bs(response.content,'html.parser')\n",
    "temperature=[]\n",
    "Temperature=soup.find_all('p',class_='temp temp-high')\n",
    "for k in Temperature:\n",
    "    weather=k.text\n",
    "    temperature.append(weather)\n",
    "temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NA\\n57°F\\n14°C\\n\\nHumidity\\n83%Wind Speed\\nNA NA MPHBarometer\\nNADewpoint\\n51°F (11°C)Visibility\\nNALast update\\n\\n                21 Jun 06:43 AM PDT            \\nMore Information:Local Forecast OfficeMore Local Wx3 Day HistoryMobile WeatherHourly Weather Forecast \\n',\n",
       " 'Today\\nPartly Sunnythen Sunnyand BreezyHigh: 69 °F\\n\\nTonight\\nIncreasingCloudsLow: 59 °F\\n\\nTuesday\\nDecreasingCloudsHigh: 70 °F\\n\\nTuesdayNight\\nPartly CloudyLow: 58 °F\\n\\nWednesday\\nSunnyHigh: 69 °F\\n\\nWednesdayNight\\nPartly CloudyLow: 56 °F\\n\\nThursday\\nSunnyHigh: 68 °F\\n\\nThursdayNight\\nPartly CloudyLow: 56 °F\\n\\nFriday\\nMostly SunnyHigh: 69 °F\\n ',\n",
       " '\\nTodayMostly cloudy, then gradually becoming sunny, with a high near 69. Breezy, with a west southwest wind 10 to 15 mph increasing to 17 to 22 mph in the afternoon. Winds could gust as high as 29 mph. TonightIncreasing clouds, with a low around 59. Southwest wind 15 to 20 mph decreasing to 8 to 13 mph after midnight. Winds could gust as high as 25 mph. TuesdayMostly cloudy, then gradually becoming sunny, with a high near 70. West southwest wind 7 to 12 mph increasing to 16 to 21 mph in the afternoon. Winds could gust as high as 26 mph. Tuesday NightPartly cloudy, with a low around 58. Southwest wind 16 to 21 mph decreasing to 10 to 15 mph after midnight. Winds could gust as high as 26 mph. WednesdaySunny, with a high near 69. West southwest wind 6 to 11 mph increasing to 12 to 17 mph in the afternoon. Winds could gust as high as 23 mph. Wednesday NightPartly cloudy, with a low around 56.ThursdaySunny, with a high near 68.Thursday NightPartly cloudy, with a low around 56.FridayMostly sunny, with a high near 69.Friday NightPartly cloudy, with a low around 57.SaturdaySunny, with a high near 72.Saturday NightPartly cloudy, with a low around 57.SundaySunny, with a high near 74. ',\n",
       " '\\nZone Area Forecast for San Francisco County, CA\\n\\nForecast Discussion\\nPrintable Forecast\\nText Only Forecast\\n\\nHourly Weather Forecast\\nTabular ForecastAir Quality Forecasts\\nInternational System of Units\\nForecast Weather Table Interface\\n\\nHourly River StagesHourly RainfallNWS Office MapWeather CalculatorUser Defined Area\\n \\n',\n",
       " 'Radar & Satellite Image\\n  \\nHourly Weather ForecastNational Digital Forecast Database\\n\\nHigh Temperature\\nChance of Precipitation \\n\\n',\n",
       " '\\n\\nClimate Monitoring \\nPast Weather \\nMonthly Temps \\nRecords \\nAstronomical Data \\nCertified Weather Data \\n\\n',\n",
       " '\\n\\nWarnings By State\\nExcessive Rainfall and Winter Weather Forecasts\\nRiver Flooding \\nLatest Warnings\\nThunderstorm/Tornado Outlook \\nHurricanes \\nFire Weather Outlooks \\nUV Alerts \\nDrought \\nSpace Weather \\nNOAA Weather Radio \\nNWS CAP Feeds \\n\\n',\n",
       " '\\n\\nRadar \\nClimate Monitoring \\nRiver Levels \\nObserved Precipitation \\nSurface Weather \\nUpper Air \\nMarine and Buoy Reports \\nSnow Cover \\nSatellite \\nSpace Weather \\nInternational Observations\\n\\n',\n",
       " '\\n\\nLocal Forecast \\nInternational Forecasts\\nSevere Weather \\nCurrent Outlook Maps \\nDrought \\nFire Weather \\nFronts/Precipitation Maps \\nCurrent Graphical Forecast Maps \\nRivers \\nMarine \\nOffshore and High Seas\\nHurricanes \\nAviation Weather \\nClimatic Outlook \\n\\n',\n",
       " '\\n\\nSpace Weather \\nDaily Briefing \\nMarine \\nClimate \\nFire Weather \\nAviation \\nForecast Models \\nWater \\nGIS\\nCooperative Observers \\nStorm Spotters \\nTsunami Warning System\\nNational Water Center\\nInternational Weather\\n\\n',\n",
       " '\\n\\nNOAA Weather Radio\\nStormReady\\nHeat \\nLightning \\nHurricanes \\nThunderstorms \\nTornadoes \\nRip Currents \\nFloods \\nTsunamis\\nTsunamiReady\\nWinter Weather \\nUltra Violet Radiation \\nAir Quality \\nDamage/Fatality/Injury Statistics \\nRed Cross \\nFederal Emergency Management Agency (FEMA) \\nBrochures \\nSafe Boating\\n\\n',\n",
       " '\\n\\nNewsroom\\nSocial Media \\nEvents\\nPubs/Brochures/Booklets \\n\\n',\n",
       " '\\n\\nNWS Education Home\\nBe A Force of Nature\\nNOAA Education Resources \\nGlossary \\nJetStream \\nNWS Training Portal \\nNOAA Library \\nFor Students, Parents and Teachers\\nBrochures \\n\\n',\n",
       " '\\n\\nOrganization \\nStrategic Plan \\nFor NWS Employees \\nInternational \\nNational Centers \\nProducts and Services \\nCareers\\nGlossary \\nContact Us \\n\\n']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature=soup.find_all('div',class_='panel-body')\n",
    "temperature_description=[]\n",
    "for k in temperature:\n",
    "    description=k.text.replace('\\n''\\n''\\n','')\n",
    "    temperature_description.append(description)\n",
    "temperature_description    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a python program to scrape fresher job listings from ‘https://internshala.com/’. It should include job title, company name, CTC, and apply date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://internshala.com/fresher-jobs'\n",
    "response=requests.get(url)\n",
    "soup=bs(response.content,'html.parser')\n",
    "job_title=[]\n",
    "company_name=[]\n",
    "CTC=[]\n",
    "title=soup.find_all('div',class_='heading_4_5 profile')\n",
    "for i in title:\n",
    "    job=i.a.text\n",
    "    job_title.append(job)\n",
    "companies=soup.find_all('div',class_='heading_6 company_name')\n",
    "for j in companies:\n",
    "    name=j.a.text.replace('\\n','')\n",
    "    company_name.append(name)\n",
    "salary=soup.find_all('div',class_='item_body')\n",
    "for k in salary:\n",
    "    amount=k.text.replace('\\nStarts\\xa0Immediately\\n','CTC,Apply_Date').replace('\\n','')\n",
    "    CTC.append(amount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Administration Associate',\n",
       " 'Recruiter',\n",
       " 'Associate Software Developer',\n",
       " 'Project Coordinator',\n",
       " 'Web Developer',\n",
       " 'Software Engineer Trainee',\n",
       " 'Business Development Specialist (Sales & Marketing)',\n",
       " 'Business Development Executive',\n",
       " 'Associate Front End Developer',\n",
       " 'Corporate Sales Executive']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['                        Global Sun                    ',\n",
       " '                        Radish Consultants Private Limited                    ',\n",
       " '                        Medico Healthcare Services & Technologies                    ',\n",
       " '                        Edupixels                    ',\n",
       " '                        Manufac Analytics Private Limited                    ',\n",
       " '                        Swabhav Techlabs                    ',\n",
       " '                        Claraeon Learning Private Limited                    ',\n",
       " '                        Picostone                    ',\n",
       " '                        AIMonk Labs Technology Limited                    ',\n",
       " '                        369 Zoss Waters                    ']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_name[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CTC,Apply_Date                        ',\n",
       " '  3 - 3.2 LPA                                                    ',\n",
       " \"21 Jul' 21\",\n",
       " 'CTC,Apply_Date                        ',\n",
       " '  3 - 5 LPA                                                    ',\n",
       " \"21 Jul' 21\",\n",
       " 'CTC,Apply_Date                        ',\n",
       " '  3 - 3.2 LPA                                                    ',\n",
       " \"21 Jul' 21\",\n",
       " 'CTC,Apply_Date                        ']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CTC[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Write a python program to scrape house details from mentioned url. It should include house title, location,area, emi and price \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2 BHK Flat  For Sale  In Purnima Elite, Electronic City In Electronic City']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url='https://www.nobroker.in/property/buy/2-bhk-apartment-for-sale-in-electronic-city-bangalore/8a9faa82782f8f690178301003ec3d53/detail'\n",
    "response=requests.get(url)\n",
    "soup=bs(response.content,'html.parser')\n",
    "house_title=[]\n",
    "title=soup.find('div',class_='nb__3A_8I').h1.text\n",
    "house_title.append(title)\n",
    "house_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gm Infinite E-City Town\\xa0 GM Infinite ECity town, Thirupalya Road, Electronic City, Bengaluru, Karnataka 560100, India'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url='https://www.nobroker.in/flats-for-sale-in-electronic_city_bangalore'\n",
    "response=requests.get(url)\n",
    "soup=bs(response.content,'html.parser')\n",
    "location=[]\n",
    "place=soup.find_all('div',class_=\"nb__2CMjv\")\n",
    "for i in place:\n",
    "    street=i.text\n",
    "    location.append(street)\n",
    "location[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,070 sqft'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url='https://www.nobroker.in/flats-for-sale-in-electronic_city_bangalore'\n",
    "response=requests.get(url)\n",
    "soup=bs(response.content,'html.parser')\n",
    "area=[]\n",
    "sft=soup.find_all('div',class_='nb__3oNyC')\n",
    "for i in sft:\n",
    "    squareft=i.text\n",
    "    area.append(squareft)\n",
    "area[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'₹33,242/Month'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url='https://www.nobroker.in/flats-for-sale-in-electronic_city_bangalore'\n",
    "response=requests.get(url)\n",
    "soup=bs(response.content,'html.parser')\n",
    "emi=[]\n",
    "EMI=soup.find_all('div',class_='font-semi-bold heading-6')\n",
    "for i in EMI:\n",
    "    interest=i.text\n",
    "    emi.append(interest)\n",
    "emi[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'₹5,421 per sq.ft.'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url='https://www.nobroker.in/flats-for-sale-in-electronic_city_bangalore'\n",
    "response=requests.get(url)\n",
    "soup=bs(response.content,'html.parser')\n",
    "price=[]\n",
    "cost=soup.find_all('div',class_='heading-7')\n",
    "for k in cost:\n",
    "    amount=k.text\n",
    "    price.append(amount)\n",
    "price[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
